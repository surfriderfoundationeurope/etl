{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitsurfridercondaa4d29431e9f947419d6d850056118d13",
   "display_name": "Python 3.6.9 64-bit ('surfrider': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "env: PGSERVER=pgdb-plastico-dev.postgres.database.azure.com\nenv: PGDATABASE=plastico-dev\nenv: PGUSERNAME=writer_user@pgdb-plastico-dev\nenv: PGPWD=SurfWriter!\n"
    }
   ],
   "source": [
    "%env PGSERVER=pgdb-plastico-dev.postgres.database.azure.com\n",
    "%env PGDATABASE=plastico-dev\n",
    "%env PGUSERNAME=writer_user@pgdb-plastico-dev\n",
    "%env PGPWD=SurfWriter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prerequesite for blob\n",
    "from azure.storage.blob import ContainerClient\n",
    "from azure.storage.blob import BlobClient\n",
    "from utils.blob import list_blob_in_container,get_blob_infos,download_blob\n",
    "# import prerequesite for ai\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from utils.ai import is_ai_ready,get_prediction,get_json_prediction,get_clean_timed_prediction,get_trash_label,map_label_to_trash_id_PG,get_trash_first_time,get_trash_time_index,get_df_prediction,get_df_manual_trash\n",
    "# import prerequesite for gps\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import json\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from tqdm import tqdm\n",
    "from utils.gps import extract_gpx_from_gopro,parse_gpx,get_gps_point_list,create_time,create_latitude,create_longitude,create_elevation,fill_gps,long_lat_to_shape_point,transform_geo,get_df_trash_gps,get_gpx_name,get_df_manual_gps\n",
    "# import prerequesite from media\n",
    "from utils.media import get_media_duration,get_media_fps\n",
    "# import prerequesite for postgre\n",
    "import os\n",
    "import psycopg2\n",
    "from utils.postgre import get_pg_connection_string,open_pg_connection,close_pg_connection,insert_trash_2,insert_trash_df,get_df_data\n",
    "# import exception\n",
    "from utils.exceptions import ETLError\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import argparse to pass parameters to main function\n",
    "import argparse\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/prediction.json') as json_file:\n",
    "    jsonPrediction = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSM Tracker GPX with Trash - no AI is required\n",
    "gpx_path = '../data/ADOUR.1_AVRIL_2019.ANTOINE_G1.gpx'\n",
    "gpx_data = parse_gpx(gpx_path)\n",
    "gps_points = gpx_data.waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_df_manual_gps(gpx_data_waypoints):\n",
    "    gps_list = []\n",
    "    for waypoint in gpx_data_waypoints:\n",
    "        gps_point = {'Time': waypoint.time, 'Latitude': waypoint.latitude,\n",
    "                              'Longitude': waypoint.longitude, 'Elevation': waypoint.elevation}\n",
    "        shape_gps_point = long_lat_to_shape_point(gps_point)\n",
    "        geo_2154 = transform_geo(shape_gps_point)\n",
    "        geo_2154_gps_point = {'Time': shape_gps_point['Time'],'the_geom':geo_2154, 'Latitude':shape_gps_point['Latitude'],'Longitude': shape_gps_point['Longitude'], 'Elevation':shape_gps_point['Elevation']}\n",
    "        gps_list.append(geo_2154_gps_point)\n",
    "    df_manual_gps = pd.DataFrame(gps_list)\n",
    "    return df_manual_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df_manual_gps(gpx_data.waypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual_gps = get_df_manual_gps(gpx_data.waypoints)\n",
    "df_manual_trash = get_df_manual_trash(gpx_data.waypoints)\n",
    "df_data = get_df_data(df_manual_trash,df_manual_gps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_manual_trash(gpx_data_waypoints):\n",
    "    trash_list = []\n",
    "    i = 0\n",
    "    for waypoint in gpx_data_waypoints:\n",
    "        trash_type_id = map_label_to_trash_id_PG(waypoint.name.lower())\n",
    "        trash = {'id':i,'label':waypoint.name,'trash_type_id':trash_type_id}\n",
    "        trash_list.append(trash)\n",
    "        i = i+1\n",
    "    df_manual_trash = pd.DataFrame(trash_list)\n",
    "    return df_manual_trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df_manual_trash(gpx_data.waypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = '28022020_Boudigau_4.MP4'\n",
    "prediction = jsonPrediction['detected_trash'][0]\n",
    "media_fps = get_media_fps(f'/tmp/{video_name}')\n",
    "gpx_path = extract_gpx_from_gopro(f'/tmp/{video_name}')\n",
    "gpx_data = parse_gpx(gpx_path)\n",
    "gps_points = get_gps_point_list(gpx_data)\n",
    "video_duration = get_media_duration(f'/tmp/{video_name}')\n",
    "video_duration_sup = int(video_duration)+1\n",
    "gps_points_filled = fill_gps(gps_points,video_duration_sup)\n",
    "time_index = get_trash_time_index(prediction,media_fps)\n",
    "# trash_gps\n",
    "trash_gps = gps_points_filled[time_index]\n",
    "shape_trash_gps = long_lat_to_shape_point(trash_gps)\n",
    "geo_2154 = transform_geo(shape_trash_gps)\n",
    "geo_2154_trash_gps = {'Time': shape_trash_gps['Time'], 'the_geom': geo_2154,'Latitude':shape_trash_gps['Latitude'],'Longitude':shape_trash_gps['Longitude'], 'Elevation': shape_trash_gps['Elevation']}\n",
    "# get trash_type from ai module\n",
    "label = get_trash_label(prediction)\n",
    "trash_type = map_label_to_trash_id_PG(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_PATH = '/tmp'\n",
    "AI_PORT = '5000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgserver = os.getenv(\"PGSERVER\")\n",
    "pgdatabase = os.getenv(\"PGDATABASE\")\n",
    "pgusername = os.getenv(\"PGUSERNAME\")\n",
    "pgpassword = os.getenv(\"PGPWD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'ADOUR.1_AVRIL_2019.ANTOINE_G1.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_gpx_name = get_gpx_name(blob_name)\n",
    "if not blob_gpx_name in os.listdir(DOWNLOAD_PATH):\n",
    "    blob_gpx_client = BlobClient.from_connection_string(conn_str=connection_string,            container_name=campaign_container_name, blob_name=blob_gpx_name)\n",
    "    download_blob(blob_gpx_client,DOWNLOAD_PATH)\n",
    "gpx_path = f'{DOWNLOAD_PATH}/{blob_gpx_name}'\n",
    "gpx_data = parse_gpx(gpx_path)\n",
    "gps_points = gpx_data.waypoints\n",
    "df_manual_gps = get_df_manual_gps(gps_points)\n",
    "df_manual_trash = get_df_manual_trash(gps_points)\n",
    "df_data = get_df_data(df_manual_trash,df_manual_gps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>trash_type_id</th>\n      <th>Time</th>\n      <th>the_geom</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Elevation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Autre dechet</td>\n      <td>0</td>\n      <td>2019-04-01 13:22:06+00:00</td>\n      <td>POINT (463575.5239753085 6235764.194847712)</td>\n      <td>43.181938</td>\n      <td>0.093354</td>\n      <td>394.293762</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Autre dechet</td>\n      <td>0</td>\n      <td>2019-04-01 13:22:07+00:00</td>\n      <td>POINT (463575.0244292183 6235764.800646954)</td>\n      <td>43.181944</td>\n      <td>0.093347</td>\n      <td>392.796753</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Autres dechets +10</td>\n      <td>8</td>\n      <td>2019-04-01 13:22:50+00:00</td>\n      <td>POINT (463604.6561084815 6235794.644867932)</td>\n      <td>43.182222</td>\n      <td>0.093698</td>\n      <td>387.526794</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Autre dechet</td>\n      <td>0</td>\n      <td>2019-04-01 13:23:28+00:00</td>\n      <td>POINT (463640.9375533302 6235825.846384096)</td>\n      <td>43.182514</td>\n      <td>0.094129</td>\n      <td>396.564392</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Autre dechet</td>\n      <td>0</td>\n      <td>2019-04-01 13:23:30+00:00</td>\n      <td>POINT (463641.0869263107 6235826.829900276)</td>\n      <td>43.182523</td>\n      <td>0.094131</td>\n      <td>396.978882</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   id               label trash_type_id                      Time  \\\n0   0        Autre dechet             0 2019-04-01 13:22:06+00:00   \n1   1        Autre dechet             0 2019-04-01 13:22:07+00:00   \n2   2  Autres dechets +10             8 2019-04-01 13:22:50+00:00   \n3   3        Autre dechet             0 2019-04-01 13:23:28+00:00   \n4   4        Autre dechet             0 2019-04-01 13:23:30+00:00   \n\n                                      the_geom   Latitude  Longitude  \\\n0  POINT (463575.5239753085 6235764.194847712)  43.181938   0.093354   \n1  POINT (463575.0244292183 6235764.800646954)  43.181944   0.093347   \n2  POINT (463604.6561084815 6235794.644867932)  43.182222   0.093698   \n3  POINT (463640.9375533302 6235825.846384096)  43.182514   0.094129   \n4  POINT (463641.0869263107 6235826.829900276)  43.182523   0.094131   \n\n    Elevation  \n0  394.293762  \n1  392.796753  \n2  387.526794  \n3  396.564392  \n4  396.978882  "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn_string = get_pg_connection_string()\n",
    "pg_connection = open_pg_connection(pg_conn_string)\n",
    "pg_cursor = pg_connection.cursor()\n",
    "# Store row_id when insert\n",
    "row_id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "90it [00:37,  2.42it/s]\n"
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "for i,row in tqdm(df_data.iterrows()):\n",
    "    try:\n",
    "        row_id = insert_trash_df(row,pg_cursor,pg_connection)\n",
    "        logger.info(row_id)\n",
    "        row_id_list.append(row_id)\n",
    "    except:\n",
    "        prediction_id = row['id']\n",
    "        logger.error(f'There was an issue inserting Trash id: {prediction_id} within PostGre')\n",
    "        logger.error(\"Early exit of ETL workflow as PG INSERT failed\")\n",
    "        exit()\n",
    "\n",
    "logger.info(f'Successfully inserted {str(len(row_id_list))} Trashes within Trash table')    \n",
    "\n",
    "# Close PG connection\n",
    "close_pg_connection(pg_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}