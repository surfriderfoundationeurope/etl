{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitsurfridercondaa4d29431e9f947419d6d850056118d13",
   "display_name": "Python 3.6.9 64-bit ('surfrider': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### azure pre-requesite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get connection_string\n",
    "import os\n",
    "connection_string = os.getenv(\"CONN_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import container client and enumerate blob within container\n",
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "def blobInContainer(connection_s,container_n):\n",
    "    campaign_container = ContainerClient.from_connection_string(conn_str=connection_s, container_name=container_n)\n",
    "    blob_list = campaign_container.list_blobs()\n",
    "    blob_names_list = []\n",
    "    for blob in blob_list:\n",
    "        blob_names_list.append(blob.name)\n",
    "    return blob_names_list\n",
    "\n",
    "blobs_campaign0 = blobInContainer(connection_string,'campaign0')\n",
    "print(blobs_campaign0)\n",
    "\n",
    "# Get Blob Video info\n",
    "from azure.storage.blob import BlobClient\n",
    "\n",
    "def blobInfos(connection_s,container_n,blob_n):\n",
    "    blob_video = BlobClient.from_connection_string(conn_str=connection_s,container_name=container_n, blob_name=blob_n)\n",
    "    blob_video_url = blob_video.url\n",
    "    blob_video_prop = blob_video.get_blob_properties()\n",
    "    blob_video_prop_keys = blob_video_prop.keys()\n",
    "    print(\"blob name:\",blob_n)\n",
    "    print(\"blob URL:\",blob_video_url)\n",
    "    print(\"blob properties:\", blob_video_prop)\n",
    "    print(\"blob properties keys:\", blob_video_prop_keys)\n",
    "\n",
    "blob_video_name = 'vid1-4K4.mp4'\n",
    "blobInfos(connection_string,'campaign0',blob_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "blob_video0 = BlobClient.from_connection_string(conn_str=connection_string,container_name=\"campaign0\", blob_name=\"vid1-4K4.mp4\")\n",
    "\n",
    "''' function to download blob from Azure to local file system'''\n",
    "''' parameter is a blob client object from azure storage sdk'''\n",
    "def downloadBlob(blobclient):\n",
    "    with open(\"/tmp/\"+blobclient.blob_name, \"wb\") as my_blob_dl:\n",
    "        blob_data = blobclient.download_blob()\n",
    "        blob_data.readinto(my_blob_dl)\n",
    "    print(\"Blob %s downloaded\" %blobclient.blob_name)\n",
    "    print(\"Blob path: /tmp/%s\" %blobclient.blob_name)\n",
    "\n",
    "downloadBlob(blob_video0)\n",
    "# this function should handle connection issue"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REST requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3777301/how-to-call-a-shell-script-from-python-code\n",
    "#https://stackoverflow.com/questions/325463/launch-a-shell-command-with-in-a-python-script-wait-for-the-termination-and-ret\n",
    "\n",
    "import subprocess\n",
    "\n",
    "''' getPrediction function sends curl request to Surfrider AI'''\n",
    "''' video name is the name of a locally downloaded video from Azure'''\n",
    "''' video name is passed as an argument to curl_request script '''\n",
    "''' curl_request script sends actual POST request to Surfrider AI'''\n",
    "def getPrediction(video_name):\n",
    "    curl_request_script = ['./curl_request_param.sh',video_name]\n",
    "    output = []\n",
    "    request_answer = subprocess.Popen(curl_request_script, stdout=subprocess.PIPE)\n",
    "    for line in request_answer.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    return output\n",
    "\n",
    "# this function should handle connection issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from AI on vid1-4K4.MP4\n",
    "prediction = getPrediction('vid1-4K4.mp4')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = getPrediction('goproshort-480p.mov')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JSON Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "''' jsonPrediction cast a prediction from getPrediction function '''\n",
    "''' and cast the list prediction as a string then dictionnary with json_loads '''\n",
    "def jsonPrediction(pred):\n",
    "    string_prediction = str(pred[0])[2:-3] #removing 2 x first and 3 last characters of pred\n",
    "    json_prediction = json.loads(string_prediction)\n",
    "    return json_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prediction = jsonPrediction(prediction)\n",
    "json_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_to_box in json_prediction['detected_trash']:\n",
    "    print(frame_to_box)\n",
    "    print(frame_to_box['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' getTrashLabel return label from a frame_to_box'''\n",
    "def getTrashLabel(frame_2_box):\n",
    "    return frame_to_box['label']\n",
    "\n",
    "test_f2b = {'frame_to_box': {'2': [0.45, 0.44, 0.5, 0.5]}, 'id': 0, 'label': 'fragments'}\n",
    "getTrashLabel(test_f2b['frame_to_box'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### requests - skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make first GET Request using requests module\n",
    "import requests\n",
    "r_get = requests.get('https://github.com/timeline.json')\n",
    "print(r_get.text)\n",
    "# Make first POST Request using requests module\n",
    "r_post = requests.post(\"http://httpbin.org/post\")\n",
    "print(r_post.text) # response in text format\n",
    "print(r_post.json()) # response is json formated\n",
    "\n",
    "# Video POST request example\n",
    "desktop = '/Users/clement/Desktop/'\n",
    "video = 'vid1-4K.MP4'\n",
    "video_path = os.path.join(desktop,video)\n",
    "url = 'http://aiapisurfrider.northeurope.cloudapp.azure.com:5000'\n",
    "myfile = {'file': open(video_path ,'rb')}\n",
    "#myairequest = requests.post(url, files = myfile)\n",
    "\n",
    "# Image POST request example\n",
    "desktop = '/Users/clement/Desktop/'\n",
    "img = 'G0061735.JPG'\n",
    "img_path = os.path.join(desktop,img)\n",
    "url = 'http://aiapisurfrider.northeurope.cloudapp.azure.com:5000'\n",
    "myfile = {'file': open(img_path ,'rb')}\n",
    "myairequest = requests.post(url, files = myfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sql odbc driver and connect to SQL DB\n",
    "import os\n",
    "import pyodbc\n",
    "server = os.getenv(\"SERVER\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"SQLPWD\")\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Query on dbo.Trash_Type\n",
    "cursor.execute(\"SELECT * FROM dbo.Trash_Type\")\n",
    "row = cursor.fetchone()\n",
    "while row:\n",
    "    print (str(row[0]))\n",
    "    print (str(row[1]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapLabel2TrashId(label):\n",
    "    switcher = { \n",
    "    \"Fishing or Hunting\":\"89B44BAA-69AA-4109-891A-128E012E7E07\",\n",
    "    \"Food Packaging\":\"185FEFA2-EEF2-47A8-873E-26032A4BB3C3\",\n",
    "    \"Unknown\":\"BB4DEA69-218A-40CC-A000-2AE17C37152C\",\n",
    "    \"Industrial or Construction Debris\":\"2A863E38-E5D0-455F-87CE-2B75DA29F59A\",\n",
    "    \"fragments\":\"ED401B92-DC24-44C0-A52A-34CE831092BF\",\n",
    "    \"Agricultural Waste\":\"36B2AFEB-7A7C-44B5-A790-5E5C73BA144D\",\n",
    "    \"others\":\"4BEC18FC-BC48-45B7-AFDA-6BA96BD80921\",\n",
    "    \"Common Household Items\":\"C68E90CF-6E65-4474-BC60-72E1C8513F55\",\n",
    "    \"plastic\":\"6961D0DB-928C-419E-9985-98EEEAF552C7\",\n",
    "    \"bottles\":\"9780940B-D06C-4AAB-8003-AB914981E87A\",\n",
    "    \"Drinking Bottles\":\"BCF549A8-AECD-4BC9-B9B8-B94A8F3758D5\",\n",
    "    \"Unknown10\":\"BC7BB564-BE04-4B4B-9913-FF69780B93A6\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trash INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated - trashInsert to take additional latitude and longitude parameters\n",
    "def trashInsert(trashTypeId,cursor,cnxn):\n",
    "    cursor.execute(\"INSERT dbo.Trash (Id,CampaignId,Latitude,Longitude,TrashTypeId,Precision,AI_Version) VALUES (NEWID(),'8D21A132-CF4B-404E-B287-C40A2F12D305','50.797731', '2.179029', ? ,'0.95','0')\",trashTypeId)\n",
    "    cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trashInsert(trashTypeId,lat,long,cursor,cnxn):\n",
    "    \"\"\" trashInsert execute INSERT request to dbo.Trash table\n",
    "    Arguments:\n",
    "        - trashTypeId: the trashTypeId of a Trash from TrashId table\n",
    "        - lat & long: the GPS coordinates of the Trash, extracted from GPX file\n",
    "        - cursor & cnxn: cursor and connection with regard to pyodbc to insert within SQL DB TrashTable\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(\"INSERT dbo.Trash (Id,CampaignId,Latitude,Longitude,TrashTypeId,Precision,AI_Version) VALUES (NEWID(),'8D21A132-CF4B-404E-B287-C40A2F12D305',?,?,?,'0.95','0')\",lat,long,trashTypeId)\n",
    "    cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing INSERT for all trash detected in json_prediction from vid1-4K4.MP4\n",
    "for frame_to_box in json_prediction['detected_trash']:\n",
    "    print(frame_to_box)\n",
    "    trashLabel = getTrashLabel(frame_to_box)\n",
    "    print(trashLabel)\n",
    "    mapLabel = mapLabel2TrashId(trashLabel)\n",
    "    print(mapLabel)\n",
    "    trashInsert(mapLabel,cursor,cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Latitude and Longitude\n",
    "lat = 50.797731\n",
    "long = 2.179029\n",
    "# Insert Trashes\n",
    "for frame_to_box in json_prediction['detected_trash']:\n",
    "    print(frame_to_box)\n",
    "    trashLabel = getTrashLabel(frame_to_box)\n",
    "    print(trashLabel)\n",
    "    mapLabel = mapLabel2TrashId(trashLabel)\n",
    "    print(mapLabel)\n",
    "    trashInsert(mapLabel,lat,long,cursor,cnxn)\n",
    "    # Increment latitude and longitude\n",
    "    lat = lat+0.001\n",
    "    long = long+0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trash End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import ContainerClient\n",
    "from azure.storage.blob import BlobClient\n",
    "import json \n",
    "import os\n",
    "import pyodbc\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' blobContainer create a name_list of blobs within container'''\n",
    "''' params are container name (no full url) & storage conn string'''\n",
    "def blobInContainer(connection_s,container_n):\n",
    "    campaign_container = ContainerClient.from_connection_string(conn_str=connection_s, container_name=container_n)\n",
    "    blob_list = campaign_container.list_blobs()\n",
    "    blob_names_list = []\n",
    "    for blob in blob_list:\n",
    "        blob_names_list.append(blob.name)\n",
    "    return blob_names_list\n",
    "\n",
    "''' blobInfos provides basic information about a blob object'''\n",
    "''' params are blob_name only (no full url) & storage conn string'''\n",
    "def blobInfos(connection_s,container_n,blob_n):\n",
    "    blob_video = BlobClient.from_connection_string(conn_str=connection_s,container_name=container_n, blob_name=blob_n)\n",
    "    blob_video_url = blob_video.url\n",
    "    blob_video_prop = blob_video.get_blob_properties()\n",
    "    blob_video_prop_keys = blob_video_prop.keys()\n",
    "    print(\"blob name:\",blob_n)\n",
    "    print(\"blob URL:\",blob_video_url)\n",
    "    print(\"blob properties:\", blob_video_prop)\n",
    "    print(\"blob properties keys:\", blob_video_prop_keys)\n",
    "\n",
    "\n",
    "''' downloadBlob from Azure to local file system'''\n",
    "''' parameter is a blob client object from azure storage sdk'''\n",
    "def downloadBlob(blobclient):\n",
    "    with open(\"/tmp/\"+blobclient.blob_name, \"wb\") as my_blob_dl:\n",
    "        blob_data = blobclient.download_blob()\n",
    "        blob_data.readinto(my_blob_dl)\n",
    "    print(\"Blob %s downloaded\" %blobclient.blob_name)\n",
    "    print(\"Blob path: /tmp/%s\" %blobclient.blob_name)\n",
    "\n",
    "\n",
    "''' getPrediction function sends curl request to Surfrider AI'''\n",
    "''' video name is the name of a locally downloaded video from Azure'''\n",
    "''' video name is passed as an argument to curl_request script '''\n",
    "''' curl_request script sends actual POST request to Surfrider AI'''\n",
    "def getPrediction(video_name):\n",
    "    curl_request_script = ['./curl_request_param.sh',video_name]\n",
    "    output = []\n",
    "    request_answer = subprocess.Popen(curl_request_script, stdout=subprocess.PIPE)\n",
    "    i = 0\n",
    "    for line in request_answer.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    return output\n",
    "\n",
    "\n",
    "''' jsonPrediction cast a prediction from getPrediction function '''\n",
    "''' from a list prediction to a string then dictionnary with json_loads '''\n",
    "def jsonPrediction(pred):\n",
    "    string_prediction = str(pred[0])[2:-3] #removing 2 x first and 3 last characters of pred\n",
    "    json_prediction = json.loads(string_prediction)\n",
    "    return json_prediction\n",
    "\n",
    "\n",
    "''' getTrashLabel return label from a frame_to_box'''\n",
    "def getTrashLabel(frame_2_box):\n",
    "    return frame_2_box['label']\n",
    "\n",
    "''' mapLabelTrashId is a switch that converts label to TrashId'''\n",
    "''' param is label that comes from AI predictions dictionnary jsonPrediction'''\n",
    "def mapLabel2TrashId(label):\n",
    "    switcher = { \n",
    "    \"Fishing or Hunting\":\"89B44BAA-69AA-4109-891A-128E012E7E07\",\n",
    "    \"Food Packaging\":\"185FEFA2-EEF2-47A8-873E-26032A4BB3C3\",\n",
    "    \"Unknown\":\"BB4DEA69-218A-40CC-A000-2AE17C37152C\",\n",
    "    \"Industrial or Construction Debris\":\"2A863E38-E5D0-455F-87CE-2B75DA29F59A\",\n",
    "    \"fragments\":\"ED401B92-DC24-44C0-A52A-34CE831092BF\",\n",
    "    \"Agricultural Waste\":\"36B2AFEB-7A7C-44B5-A790-5E5C73BA144D\",\n",
    "    \"others\":\"4BEC18FC-BC48-45B7-AFDA-6BA96BD80921\",\n",
    "    \"Common Household Items\":\"C68E90CF-6E65-4474-BC60-72E1C8513F55\",\n",
    "    \"plastic\":\"6961D0DB-928C-419E-9985-98EEEAF552C7\",\n",
    "    \"bottles\":\"9780940B-D06C-4AAB-8003-AB914981E87A\",\n",
    "    \"Drinking Bottles\":\"BCF549A8-AECD-4BC9-B9B8-B94A8F3758D5\",\n",
    "    \"Unknown10\":\"BC7BB564-BE04-4B4B-9913-FF69780B93A6\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")\n",
    "\n",
    "\n",
    "''' trashInsert execute INSERT request to dbo.Trash table'''\n",
    "''' parameter to indsert is a trashTypeId defined in Trash_Type table'''\n",
    "def trashInsert(cursor,cnxn,trashTypeId):\n",
    "    cursor.execute(\"INSERT dbo.Trash (Id,CampaignId,Latitude,Longitude,TrashTypeId,Precision,AI_Version) VALUES (NEWID(),'8D21A132-CF4B-404E-B287-C40A2F12D305','50.797731', '2.179029', ? ,'0.95','0')\",trashTypeId)\n",
    "    cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # blob storage connection string\n",
    "    connection_string = os.getenv(\"CONN_STRING\")\n",
    " \n",
    "    # get list of blobs in container campaign0\n",
    "    campaign_container_name = 'campaign0'\n",
    "    #campaign_container_name = 'campaign1'\n",
    "    blobs_campaign0 = blobInContainer(connection_string,campaign_container_name)\n",
    "    print(blobs_campaign0)\n",
    "\n",
    "    # get infos of blob video vid1-4K.MP4,vid1-4K2.MP4,vid1-4K3.mp4,vid1-4K4.mp4,19022020_Adour_6.mp4\n",
    "#    blob_video_name = '19022020_Adour_6.mp4'\n",
    "    blob_video_name = 'vid1-480p.mov'   \n",
    "    blobInfos(connection_string,campaign_container_name,blob_video_name)\n",
    "\n",
    "    # download blob video\n",
    "    blob_video0 = BlobClient.from_connection_string(conn_str=connection_string,container_name=campaign_container_name, blob_name=blob_video_name)\n",
    "    downloadBlob(blob_video0)\n",
    "\n",
    "    # get predictions from AI on vid1-4K4.MP4\n",
    "    prediction = getPrediction(blob_video_name)\n",
    "\n",
    "    # cast prediction to JSON/Dictionnary format\n",
    "    json_prediction = jsonPrediction(prediction)\n",
    "    json_prediction\n",
    "\n",
    "    # SQL connection\n",
    "    server = os.getenv(\"SERVER\")\n",
    "    database = os.getenv(\"DATABASE\")\n",
    "    username = os.getenv(\"USERNAME\")\n",
    "    password = os.getenv(\"SQLPWD\")\n",
    "    driver= '{ODBC Driver 17 for SQL Server}'\n",
    "    cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    # Executing INSERT for all trash detected in json_prediction from vid1-4K4.MP4\n",
    "    for frame_to_box in json_prediction['detected_trash']:\n",
    "        print(frame_to_box)\n",
    "        trashLabel = getTrashLabel(frame_to_box)\n",
    "        print(trashLabel)\n",
    "        mapLabel = mapLabel2TrashId(trashLabel)\n",
    "        print(mapLabel)\n",
    "        trashInsert(cursor,cnxn,mapLabel)\n",
    "    \n",
    "    # Visualize main result within dbo.Trash Table\n",
    "    cursor.execute(\"SELECT * FROM dbo.Trash\")\n",
    "    row = cursor.fetchone()\n",
    "    while row:\n",
    "        print (str(row[0]))\n",
    "        row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SQL Ops - Optional check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Prequesite\n",
    "server = os.getenv(\"SERVER\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"SQLPWD\")\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT all record from dbo.Trash\n",
    "cursor.execute(\"SELECT * FROM dbo.Trash\")\n",
    "row = cursor.fetchone()\n",
    "while row:\n",
    "    for i in range(0,5):\n",
    "        print (str(row[i]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE ALL RECORD from Trash table\n",
    "cursor.execute(\"DELETE FROM dbo.Trash\")\n",
    "cnxn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostGre SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Update connection string information from env variables\n",
    "pgserver = os.getenv(\"PGSERVER\")\n",
    "pgdatabase = os.getenv(\"PGDATABASE\")\n",
    "pgusername = os.getenv(\"PGUSERNAME\")\n",
    "pgpassword = os.getenv(\"PGPWD\")\n",
    "sslmode = \"require\"\n",
    "\n",
    "# Construct connection string with psycopg2\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(pgserver, pgusername, pgdatabase, pgpassword, sslmode)\n",
    "conn = psycopg2.connect(conn_string) \n",
    "print(\"Connection established\")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first x 10 records of PostGre public.Trash table\n",
    "cursor.execute(\"SELECT * FROM public.Trash\")\n",
    "row = cursor.fetchone()\n",
    "\n",
    "for k in range(0,10):\n",
    "    for i in range(0,5):\n",
    "        print (str(row[i]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT REQUEST: no paramater\n",
    "def trashInsert(cursor,connexion):\n",
    "    id = cursor.execute(\"INSERT INTO public.trash (id, id_ref_campaign_fk,the_geom, elevation, id_ref_trash_type_fk,brand_type ) VALUES (DEFAULT, 'fb367e0e-9b56-4418-9b80-5acd5c239754','POINT (468232.3142275742 6221584.069506371)','610.109375',1,'perrier') RETURNING id;\")\n",
    "    connexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing simple Trash Insert in PostGre\n",
    "trashInsert(cursor,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT REQUEST: point parameter\n",
    "def trashInsert(the_geom,cursor,connexion):\n",
    "    point = 'POINT(' + str(the_geom.coords.xy[0][0]) + ' ' + str(the_geom.coords.xy[1][0]) + ')'\n",
    "    cursor.execute(\"INSERT INTO public.trash (id, id_ref_campaign_fk,the_geom, elevation, id_ref_trash_type_fk,brand_type ) VALUES (DEFAULT, 'fb367e0e-9b56-4418-9b80-5acd5c239754',%s,'610.109375',1,%s) RETURNING id;\", (point,'oasis'))\n",
    "    connexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Trash Insert with shapely python Point in PostGre\n",
    "from shapely.geometry import Point\n",
    "geopoint = Point(0.0,1.0)\n",
    "trashInsert(geopoint,cursor,conn)"
   ]
  }
 ]
}